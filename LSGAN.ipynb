{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "underlying-affect",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-lqagy1sj because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, ActivityRegularization, Lambda, Concatenate, Permute, Convolution1D, MaxPooling1D, AveragePooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import concatenate, dot\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Lambda, concatenate, Add\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, LeakyReLU\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "from matplotlib.colors import LogNorm\n",
    "import pylab as pyy\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcol\n",
    "\n",
    "# import pylab as py\n",
    "# from tools import load, save, checkdir\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "meaning-creation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"inverse_mappers/GAN/eICU_age.npy\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "disciplinary-cartridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= data['age']\n",
    "data= np.array(data).reshape(-1,1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bridal-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler, QuantileTransformer, PowerTransformer\n",
    "data_sc= QuantileTransformer(output_distribution='normal')# minmax\n",
    "data_scaled = data_sc.fit_transform(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lucky-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "clas = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "immune-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSGAN():\n",
    "    def __init__(self):\n",
    "        self.img_shape = (clas.shape[1],)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.00001, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        generator_noise = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(generator_noise)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model(generator_noise, valid )\n",
    "        # (!!!) Optimize w.r.t. MSE loss instead of crossentropy\n",
    "#         MMD_loss = self.MMD_loss()\n",
    "        self.combined.compile(loss='mse', optimizer=optimizer)\n",
    "        \n",
    "    \n",
    "\n",
    "    def build_generator(self):\n",
    "        noise = Input(shape=(100,))\n",
    "        \n",
    "        rate = 0.000000000001\n",
    "        x11 = Dense(512)(noise)\n",
    "        x1 = BatchNormalization(momentum=0.8)(x11)\n",
    "        x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "        \n",
    "\n",
    "        x2 = Dense(512)(x1)\n",
    "        x2 = BatchNormalization(momentum=0.8)(x2)\n",
    "        x2 = LeakyReLU(alpha=0.2)(x2)\n",
    "        \n",
    "\n",
    "        x3 = Dense(512)(x2)\n",
    "         \n",
    "        sc11 = Add()([x11, x3])\n",
    "        sc1 = BatchNormalization(momentum=0.8)(sc11)\n",
    "        sc1 = LeakyReLU(alpha=0.2)(sc1)\n",
    "        \n",
    "\n",
    "        x4 = Dense(512)(sc1)\n",
    "        x4 = BatchNormalization(momentum=0.8)(x4)\n",
    "        x4 = LeakyReLU(alpha=0.2) (x4)\n",
    "        \n",
    "        \n",
    "        x5 = Dense(512)(x4)\n",
    "        \n",
    "        sc22 = Add()([sc11, x5])\n",
    "        sc2 = BatchNormalization(momentum=0.8)(sc22)\n",
    "        sc2 = LeakyReLU(alpha=0.2)(sc2)\n",
    "        \n",
    "        x6 = Dense(512)(sc2)\n",
    "        x6 = BatchNormalization(momentum=0.8)(x6)\n",
    "        x6 = LeakyReLU(alpha=0.2) (x6)\n",
    "        \n",
    "        x7 = Dense(512)(x6)\n",
    "        \n",
    "        sc33 = Add()([sc22, x7])\n",
    "        sc3 = BatchNormalization(momentum=0.8)(sc33)\n",
    "        sc3 = LeakyReLU(alpha=0.2)(sc3)\n",
    "        \n",
    "        \n",
    "        x8 = Dense(512)(sc3)\n",
    "        x8 = BatchNormalization(momentum=0.8)(x8)\n",
    "        x8 = LeakyReLU(alpha=0.2) (x8)\n",
    "        \n",
    "        x9 = Dense(512)(x8)\n",
    "        \n",
    "        sc44 = Add()([sc33, x9])\n",
    "        sc4 = BatchNormalization(momentum=0.8)(sc44)\n",
    "        sc4 = LeakyReLU(alpha=0.2)(sc4)\n",
    "        \n",
    "        \n",
    "\n",
    "        output = Dense(1)(sc4)\n",
    "        #features = Lambda(self.feature_mul)(output2)\n",
    "        #outputmerge = concatenate([output2, features])\n",
    "        generator = Model(inputs=noise, outputs=[output,sc4 ])\n",
    "        generator.summary()\n",
    "        return(generator)\n",
    "\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        rate = 0.2\n",
    "        \n",
    "        vis = Input(shape=(clas.shape[1],))\n",
    "        \n",
    "        x11 = Dense(512)(vis)\n",
    "        #x1 = BatchNormalization(momentum=0.8)(x11)\n",
    "        x1 = LeakyReLU(alpha=0.2)(x11)\n",
    "        x1 = Dropout(rate)(x1)\n",
    "        \n",
    "\n",
    "        x2 = Dense(512)(x1)\n",
    "        #x2 = BatchNormalization(momentum=0.8)(x2)\n",
    "        x2 = LeakyReLU(alpha=0.2)(x2)\n",
    "        x2 = Dropout(rate)(x2)\n",
    "        \n",
    "\n",
    "        x3 = Dense(512)(x2)\n",
    "         \n",
    "        sc11 = Add()([x11, x3])\n",
    "        #sc1 = BatchNormalization(momentum=0.8)(sc11)\n",
    "        sc1 = LeakyReLU(alpha=0.2)(sc11)\n",
    "        sc1 = Dropout(rate)(sc1)\n",
    "        \n",
    "\n",
    "        x4 = Dense(512)(sc1)\n",
    "        #x4 = BatchNormalization(momentum=0.8)(x4)\n",
    "        x4 = LeakyReLU(alpha=0.2) (x4)\n",
    "        x4 = Dropout(rate)(x4)\n",
    "        \n",
    "        \n",
    "        x5 = Dense(512)(x4)\n",
    "        \n",
    "        sc22 = Add()([sc11, x5])\n",
    "        #sc2 = BatchNormalization(momentum=0.8)(sc22)\n",
    "        sc2 = LeakyReLU(alpha=0.2)(sc22)\n",
    "        sc2 = Dropout(rate)(sc2)\n",
    "        \n",
    "        \n",
    "        x6 = Dense(512)(sc2)\n",
    "        #x6 = BatchNormalization(momentum=0.8)(x6)\n",
    "        x6 = LeakyReLU(alpha=0.2) (x6)\n",
    "        x6 = Dropout(rate)(x6)\n",
    "        \n",
    "        \n",
    "        x7 = Dense(512)(x6)\n",
    "        \n",
    "        sc33 = Add()([sc22, x7])\n",
    "        #sc3 = BatchNormalization(momentum=0.8)(sc33)\n",
    "        sc3 = LeakyReLU(alpha=0.2)(sc33)\n",
    "        sc3 = Dropout(rate)(sc3)\n",
    "        \n",
    "        \n",
    "        x8 = Dense(512)(sc3)\n",
    "        #x8 = BatchNormalization(momentum=0.8)(x8)\n",
    "        x8 = LeakyReLU(alpha=0.2) (x8)\n",
    "        x8 = Dropout(rate)(x8)\n",
    "        \n",
    "        x9 = Dense(512)(x8)\n",
    "        \n",
    "        sc44 = Add()([sc33, x9])\n",
    "        #sc4 = BatchNormalization(momentum=0.8)(sc44)\n",
    "        sc4 = LeakyReLU(alpha=0.2)(sc44)\n",
    "        sc4 = Dropout(rate)(sc4)\n",
    "        \n",
    "        # (!!!) No softmax\n",
    "        output = Dense(1)(sc4)\n",
    "\n",
    "        discriminator = Model(inputs=vis, outputs=[output,sc4])\n",
    "        discriminator.summary()\n",
    "        return(discriminator)\n",
    "    \n",
    "    \n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "        \n",
    "                  \n",
    "        X_train = clas\n",
    "        print(X_train.shape)\n",
    "        \n",
    "\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "#         self.generator.load_weights('ls_generator.h5')\n",
    "#         self.discriminator.load_weights('ls_discriminator.h5')\n",
    "        \n",
    "        dloss=[]\n",
    "        gloss=[]\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            gen_imgs = self.generator.predict(noise, verbose = 0)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = self.combined.train_on_batch(noise, [valid, imgs])\n",
    "\n",
    "            # Plot the progress\n",
    "            #print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            #loss_gen.append(g_loss[0])\n",
    "            #loss_dis.append(d_loss[0])\n",
    "            \n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            dloss=np.append(dloss,d_loss[0])\n",
    "            gloss=np.append(gloss,g_loss)\n",
    "            if epoch % sample_interval == 0:\n",
    "                print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "                self.sample_images(epoch, dloss, gloss)\n",
    "                #self.generator.save_weights('/work/JAM/yasir/models/ls_generator_res_error_fixed_0.h5')\n",
    "                #self.discriminator.save_weights('/work/JAM/yasir/models/ls_discriminator_res_error_fixed_0.h5')\n",
    "                \n",
    "                #self.generator.save_weights('ls_generator_fat_free.h5')\n",
    "                #self.discriminator.save_weights('ls_discriminator_fat_free.h5')\n",
    "                \n",
    "                print('saved ...')\n",
    "                \n",
    "#                 self.discriminator.save_weights('ls_discriminator_all'+str(epoch)+'.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def sample_images(self, epoch, dloss, gloss):\n",
    "\n",
    "        SAMPLE_SIZE = clas.shape[0] \n",
    "        noise = np.random.normal(0, 1, (SAMPLE_SIZE, 100))\n",
    "        \n",
    "\n",
    "        results = self.generator.predict(noise, batch_size = 20000)\n",
    "        \n",
    "        plt.hist(np.round(data_sc.inverse_transform(results)), bins = 100, histtype = 'step',label=\"GAN\")\n",
    "        plt.hist(data, bins = 100, histtype = 'step', label= \"True\")\n",
    "        plt.xlim(data.min(),data.max())\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "  \n",
    "\n",
    "        nrows,ncols=1,1\n",
    "        fig = pyy.figure(figsize=(ncols*7,nrows*5))\n",
    "\n",
    "        ax=pyy.subplot(nrows,ncols,1)\n",
    "        ax.plot(range(1,len(gloss)+1),gloss,label=r'$\\rm generator$')\n",
    "        ax.plot(range(1,len(dloss)+1),dloss,label=r'$\\rm discriminator$')\n",
    "        ax.semilogy()\n",
    "        ax.semilogx()\n",
    "        ax.legend(fontsize=20)\n",
    "        ax.set_ylabel(r'$\\rm Loss$',size=20)\n",
    "        ax.set_xlabel(r'$\\rm epochs$',size=20)\n",
    "        ax.tick_params(axis='both', which='both', labelsize=15,direction='in')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "every-stroke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 512)          1024        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)     (None, 512)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 512)          0           ['leaky_re_lu_18[0][0]']         \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 512)          262656      ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)     (None, 512)          0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 512)          0           ['leaky_re_lu_19[0][0]']         \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 512)          262656      ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 512)          0           ['dense_20[0][0]',               \n",
      "                                                                  'dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)     (None, 512)          0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 512)          0           ['leaky_re_lu_20[0][0]']         \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 512)          262656      ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)     (None, 512)          0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 512)          0           ['leaky_re_lu_21[0][0]']         \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 512)          262656      ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 512)          0           ['add_8[0][0]',                  \n",
      "                                                                  'dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_22 (LeakyReLU)     (None, 512)          0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 512)          0           ['leaky_re_lu_22[0][0]']         \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 512)          262656      ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_23 (LeakyReLU)     (None, 512)          0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 512)          0           ['leaky_re_lu_23[0][0]']         \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 512)          262656      ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 512)          0           ['add_9[0][0]',                  \n",
      "                                                                  'dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_24 (LeakyReLU)     (None, 512)          0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 512)          0           ['leaky_re_lu_24[0][0]']         \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 512)          262656      ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_25 (LeakyReLU)     (None, 512)          0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 512)          0           ['leaky_re_lu_25[0][0]']         \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 512)          262656      ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 512)          0           ['add_10[0][0]',                 \n",
      "                                                                  'dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_26 (LeakyReLU)     (None, 512)          0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 512)          0           ['leaky_re_lu_26[0][0]']         \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 1)            513         ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,102,785\n",
      "Trainable params: 2,102,785\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 512)          51712       ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 512)         2048        ['dense_30[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_27 (LeakyReLU)     (None, 512)          0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 512)          262656      ['leaky_re_lu_27[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 512)         2048        ['dense_31[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_28 (LeakyReLU)     (None, 512)          0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 512)          262656      ['leaky_re_lu_28[0][0]']         \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 512)          0           ['dense_30[0][0]',               \n",
      "                                                                  'dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 512)         2048        ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_29 (LeakyReLU)     (None, 512)          0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 512)          262656      ['leaky_re_lu_29[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 512)         2048        ['dense_33[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_30 (LeakyReLU)     (None, 512)          0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 512)          262656      ['leaky_re_lu_30[0][0]']         \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 512)          0           ['add_12[0][0]',                 \n",
      "                                                                  'dense_34[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 512)         2048        ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_31 (LeakyReLU)     (None, 512)          0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 512)          262656      ['leaky_re_lu_31[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 512)         2048        ['dense_35[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_32 (LeakyReLU)     (None, 512)          0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 512)          262656      ['leaky_re_lu_32[0][0]']         \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 512)          0           ['add_13[0][0]',                 \n",
      "                                                                  'dense_36[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 512)         2048        ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_33 (LeakyReLU)     (None, 512)          0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 512)          262656      ['leaky_re_lu_33[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 512)         2048        ['dense_37[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_34 (LeakyReLU)     (None, 512)          0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 512)          262656      ['leaky_re_lu_34[0][0]']         \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 512)          0           ['add_14[0][0]',                 \n",
      "                                                                  'dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 512)         2048        ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_35 (LeakyReLU)     (None, 512)          0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 1)            513         ['leaky_re_lu_35[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,171,905\n",
      "Trainable params: 2,162,689\n",
      "Non-trainable params: 9,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan = LSGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "equal-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# gan.generator.save_weights('/work/JAM/almaeen/ls_generato.h5')\n",
    "# gan.discriminator.save_weights('/work/JAM/almaeen/ls_discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "valid-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator.load_weights('/work/JAM/almaeen/ls_generato.h5')\n",
    "gan.discriminator.load_weights('/work/JAM/almaeen/ls_discriminator.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "comprehensive-technical",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gan.train(epochs=5000000, batch_size=128, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "advisory-aurora",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 284ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SAMPLE_SIZE = clas.shape[0] \n",
    "noise = np.random.normal(0, 1, (SAMPLE_SIZE, 100))\n",
    "\n",
    "\n",
    "results, LL = gan.generator.predict(noise, batch_size = 20000)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "irish-examination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJcAAAGkCAYAAACM38RMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA5N0lEQVR4nO3de5idZX0v/O8Po2BAMAQ8VUnUFlSs1TYWhZZjt68nEAV90/0i2l3D1o2VxFO5KrKBqoXd1sRjKakFK7agdIvQKkpBpZ4btRdaFKGSUaqghABCQE73+8dag+M4k1lZmTWn9flc17qezPPczzO/lXVnZc137vt+qrUWAAAAAOjHDrNdAAAAAADzl3AJAAAAgL4JlwAAAADom3AJAAAAgL4JlwAAAADo26LZLmAQ9thjj7Z8+fLZLgMAAABgwfja1752U2ttz/H7F2S4tHz58mzYsGG2ywAAAABYMKpqZKL9psUBAAAA0DfhEgAAAAB9Ey4BAAAA0DfhEgAAAAB9Ey4BAAAA0DfhEgAAAAB9Ey4BAAAA0DfhEgAAAAB9Ey4BAAAA0DfhEgAAAAB9Ey4BAAAA0DfhEgAAAAB9Ey4BAAAA0DfhEgAAAAB9Ey4BAAAA0DfhEgAAAAB9WzTbBQAAAADMFctPXJ6RTSNTtlu2dFk2nr5x8AXNA8IlAAAAgK6RTSNp69uU7WpVzUA184NpcQAAAAD0TbgEAAAAQN+ESwAAAAD0TbgEAAAAQN8s6A0AzLpe78oy17lrDAAwjIRLAMCs6/WuLHPdTN015v7778/HP/7xXHzxxfnyl7+cG2+8Mbfddlt22WWX/Mqv/Eqe8Yxn5LnPfW4OP/zw7LrrrlNeb7/99stXv/rVJMlZZ52VVatWbbX9xo0b8/jHP/6Br9euXZvVq1dP2v7ggw/O5z73ubziFa/IOeec09NzBADmD9PiAADmka985St5ylOekpe85CU5++yz8+1vfzu33nprdt1119x55535j//4j5x77rk55phj8rjHPS5r167d6vW+9a1vPRAsJcnf/u3fbnNNb3/72/PTn/50m88DABYG4RIAwDxx4YUX5sADD8zVV1+dpUuX5k//9E/zrW99K/fcc082bdqUu+66KzfeeGMuuOCCvOhFL8rtt9+e888/f6vX/MAHPpAkeeUrX5mHPexh+fKXv5yrrrpqm+q66aab8ud//ud9Py8AYH4TLgEAzAPf+c53cswxx+Tuu+/O0572tFx55ZU56aSTsu+++6bq59PxHvGIR+Soo47KhRdemCuvvDLPfvazJ73m3XffnXPPPTdJ8upXvzpHHXVUkp8HTr144QtfmCR55zvfmRtvvLGfpwYAzHPCJQCAeeCkk07KHXfckZ133jkf+9jH8pjHPGbKc/bdd9+tTov7+Mc/nptuuin77LNP9ttvv7ziFa9Ikpx77rm55557eqrr+OOPz+Me97jccccdOe2003p7MgDAgiJcAgCY4370ox/l//7f/5skefnLX54nPOEJ03Ld0RFKxx57bJLkoIMOyrJly/LjH/84F198cU/X2GmnnR4IldavX5///M//nJbaAID5Q7gEADDHfeYzn0lrnbvpHXHEEdNyzR/84Ae59NJLU1U55phjkiRV9UDQtC1T44499tjsu+++ueeee/KWt7xlWuoDAOYP4RIAwBw3doHtpz/96dNyzbPPPjv3339/DjnkkOy1114P7B8Nlz71qU/lhz/8YU/X2mGHHfKOd7wjSfKRj3wkX//616elRgBgfhAuAQDMcZs2bXrgz7vvvvuEba699to86lGPmvDxxS9+8RfattZy9tlnJ/l5mDTqV3/1V7P//vvnvvvuyznnnNNzjUcccUQOOOCAtNZy4okn9nweADD/CZcAABaAe++9NzfeeOOEj7vvvvsX2l5++eXZuHFjdt555wfuEDfW6MLeowFUr04//fQkyaWXXprLLrusz2cCAMw3i2a7AAAAtm7p0qUP/Pnmm2/Oox/96F9q86QnPemBdZmSZOPGjXn84x8/4fVG11N68YtfnF122eWXjr/sZS/LCSeckGuvvTaf+9znctBBB/VU5+/8zu/k8MMPz8UXX5wTTzwxX/3qV1NVPZ0LAHPJusvWzXYJ84qRSwAAc9xTnvKUB/787//+79t1rc2bN+djH/tYkuTcc89NVf3SY8mSJbnrrruSbNvC3knyjne8IzvssEM2bNiQj370o9tVKwAwPwiXAADmuEMOOeSBEUAXXXTRdl3rwx/+8APBUS8uuOCC3HbbbT23f+pTn/rAOk4nnXRS7r333m2uEQCYX4RLAABz3KMf/ei85CUvSZJ86EMfynXXXdf3tUZHIp1wwgn56U9/Ounj1ltvzZ577pk777wz//AP/7BN3+PUU0/NjjvumGuuuSbr16/vu1YAYH4QLgEAzANve9vbsvPOO+eOO+7IkUcemR/+8IfbfI2vf/3rD0yr+/3f//3ssssukz523XXXBwKtbZ0at9dee+X4449Pkpx22mnZsmXLNtcKAMwfwiUAgHngSU96Us4999w85CEPyZVXXpmnPe1pedvb3pb/+I//+IWFvG+77bZccskl+aM/+qNfusZoSLRs2bLst99+U37Pl73sZUmSf/u3f8u3vvWtbar3LW95S3bbbbfccMMN+bd/+7dtOhcAmF+ESwAA88SRRx6Zz33uc9lnn32yadOmvPWtb81Tn/rUPPjBD84ee+yR3XbbLbvttlue97zn5Z/+6Z/ysIc9LH/6p3+aZz3rWbnrrrvy93//90mSo48+uqfvd9BBB+URj3hEkm0fvbT77rvnzW9+87Y9QQBgXlo02wUAACxbuiy1av7fsn7Z0mUD/x7PetazctVVV+XCCy/MxRdfnC9/+cu58cYbc+utt2aXXXbJk5/85Pzmb/5mnvOc5+Soo47KzjvvnKSzkPctt9yS5OcjkqbyoAc9KC95yUty5pln5txzz80ZZ5yRhzzkIT3Xunr16rz3ve/Nj370o21+ngDA/FFjh1EvFCtWrGgbNmyY7TIAAACAeaZWVdauXDtluzXnrUlbv/Ayla2pqq+11laM329aHAAAAAB9Ey4BAAAA0DfhEgAAAAB9Ey4BAAAA0Leew6WqOrqq3lNV/1pVt1VVq6pzJ2n7a1X1x1V1eVX9oKrurqobq+rjVXXIFN/nFVX11aq6vapurarPVtULt/WJAQAAADB42zJy6aQkr03y9CT/NUXbP01yepJHJvlEkr9M8oUkL0hyeVW9bqKTquovkpyT5NFJ1ic5N8mvJ7m4ql67DbUCAAAAMAMWbUPbNUmuT3JtkoOSfGYrbS9JckZr7Rtjd1bVQUkuTfLnVfXR1tqPxhzbP8kbkvxnkme21jZ39/95kq8l+Yuq+qfW2sZtqBkAAACAAep55FJr7TOttWtaa62HtueMD5a6+z+X5LNJHpJk/3GHX93dvn00WOqeszHJ+5LsmOQPeq0XAAAAgMGbjQW97+lu7x23/9Du9pIJzvnkuDYAAAAAzAEzGi5V1bIkhyXZkuSKMft3TvIrSW4fO1VujGu6270HXiQAAAAAPZuxcKmqdkzy4XSmt50ydupbkt2621snOX10/8O3cv3jqmpDVW34yU9+sr3lAgAAANCDGQmXqupBST6U5IAk5yf5i+n+Hq21s1prK1prK/bcc8/pvjwAAAAAExh4uNQNls5N8tIkH0lyzASLgo+OTNotExvdf8u0FwgAAABA3wYaLlXVg5P8Q5KVSf4+yX9vrY1fyDuttTuS/FeSXarq0RNc6te62+8OqlYAAAAAtt3AwqWqekiSj6YzYunvkry8tXbfVk65vLt97gTHnjeuDQAAAABzwEDCpe7i3R9L8qIkH0jyB621+6c47czu9i1VtWTMtZYnOT7Jz5KcPf3VAgAAANCvRb02rKojkxzZ/fJR3e2zq+qc7p9vaq29sfvnM5M8P8lN6Ux3O7mqxl/ys621z45+0Vr7YlW9M8nrk1xZVRckeUiS/zfJ7kn+qLW2sdd6AQAAABi8nsOlJE9P8opx+57QfSTJSJLRcOnx3e0eSU7eyjU/O/aL1tobquqb6YxUOi7J/Um+nuTPW2v/tA21AgDzyLrL1s12CdNi9WGrp/V6E/xyrmdnn312XvnKV05fMQAAk+g5XGqtnZLklB7bHtxfOUlr7Zwk5/R7PgDAQvHIRz5ywv2333577rjjjq22eehDHzqwugAAxtqWkUsAAMygG264YcL9p5xySk499dSttgEAmCkDu1scAAAAAAufcAkAYIGpqlRVPvvZz+bHP/5xXv/612fvvffO4sWLf2Edp4MPPjhVlVNOOWXSa51yyimpqhx88MGTttm4cWNWr16dfffdN7vssksWL16cJz3pSTnhhBPy/e9/fxqfGQAwF5kWBwCwQF177bVZuXJlbrzxxuy000558IMfPO3f48Mf/nD+8A//MD/72c+SJDvuuGN22GGHXH311bn66qtz9tln54ILLshznvOcaf/eAMDcYOQSAMACtWbNmjz84Q/PZZddljvuuCO33XZbrr766mm7/qWXXppjjz029913X9785jfnuuuuy5133pk77rgj3/nOd/LSl740P/3pT/PSl77UCCYAWMCESwAAC9QOO+yQf/mXf8mhhx6aHXbofOzbe++9p+Xa999/f44//vjcf//9ed/73pczzjgjy5cvf2BK3j777JOPfOQjOeKII3Lbbbflne9857R8XwBg7hEuAQAsUC9/+cvz2Mc+diDXvuKKK3LNNddkjz32yKte9apJ2x177LFJkk996lMDqQMAmH3WXAIAWKAOOOCAgV37C1/4QpLk1ltvzWMe85hJ2919991JkpGRkYHVAgDMLuESAMAC9YhHPGJg1/7hD3+YJLnnnnty4403Ttn+zjvvHFgtAMDsMi0OAGCBetCDHjSwa993331Jkv322y+ttZ4eAMDCJFwCABhSixZ1BrHfddddk7a59dZbJ9z/qEc9KonpbgCAcAkAYGgtWbIkSfKDH/xg0jZf+cpXJtw/up7TDTfckA0bNkx/cQDAvCFcAgAYUr/xG7+RpHMntzvuuOOXjl9++eX50pe+NOG5hxxySH71V381SbJmzZoHFu6ezM0337yd1QIAc5VwCQBgSL3sZS/LDjvskE2bNuX3f//3c/311yfpLL79wQ9+MC9+8Yuz++67T3juokWLcuaZZ2bRokX5/Oc/nwMPPDCXXXZZ7rnnngfafO9738uZZ56ZZz7zmXn/+98/I88JAJh5wiUAgCG1995756STTkqSXHzxxXnc4x6Xhz/84dl1113zyle+Moceemj+1//6X5Oef9hhh+WjH/1oHvawh+UrX/lKfu/3fi8777xz9thjj+y000554hOfmNe85jXZsGFDqmqmnhYAMMMWzXYBAACrD1s92yUMrVNPPTW/9mu/lve973355je/mfvuuy9Pf/rT86pXvSrHHXdcTj311K2ef+SRR+baa6/N+9///nzyk5/MNddck1tuuSU777xznvSkJ+WZz3xmXvCCF+T5z3/+DD0jAGCm1UK8LeyKFSuahSUBAACAbVWrKmtXrp2y3Zrz1qStX3iZytZU1ddaayvG7zctDgAAAIC+CZcAAAAA6JtwCQAAAIC+CZcAAAAA6JtwCQAAAIC+CZcAAAAA6JtwCQAAAIC+CZcAAAAA6JtwCQAAAIC+CZcAAAAA6JtwCQAAAIC+CZcAAAAA6JtwCQAAAIC+CZcAAAAA6JtwCQAAAIC+CZcAAAAA6JtwCQAAAIC+CZcAAAAA6JtwCQAAAIC+CZcAAAAA6JtwCQAAAIC+CZcAAAAA6JtwCQAAAIC+9RQuVdXRVfWeqvrXqrqtqlpVnTvFOftX1Seq6uaqurOqrqyq1VX1oK2c88Kq+mxV3VpVt1fVV6rqFdv6pAAAAACYGYt6bHdSkt9IcnuS65M8aWuNq+pFSf4xyV1Jzk9yc5LDk6xNckCSl05wzmuTvCfJpiTnJrk7ydFJzqmqX2+tvbHHWgEAAACYIb1Oi1uTZO8kuyZ5zdYaVtWuSdYnuS/Jwa21P2ytvSnJ05N8KcnRVbVy3DnLk/xFOiHUitba8a21NUmeluQ/k7yhqp7d65MCAAAAYGb0FC611j7TWrumtdZ6aH50kj2TnNda2zDmGnelMwIq+eWA6n8k2THJe1trG8ecsznJO7pfvrqXWgEAAACYOYNY0PvQ7vaSCY5dkWRLkv2rascez/nkuDYAAAAAzBGDCJf26W6/O/5Aa+3eJNels9bTE3o850dJ7kjy2KpaPNk3rarjqmpDVW34yU9+0m/tAAAAAGyDQYRLu3W3t05yfHT/w/s4Z7dJjqe1dlZrbUVrbcWee+7ZS50AAAAAbKdBhEsAAAAADIlBhEtTjTIa3X9LH+dMNrIJAAAAgFkwiHDp6u527/EHqmpRkscnuTfJ93o859FJdk5yfWtty/SWCgAAAMD2GES4dHl3+9wJjh2YZHGSL7bWftbjOc8b1wYAAACAOWIQ4dIFSW5KsrKqVozurKqdkryt++VfjTvn7CQ/S/Laqlo+5pwlSf6k++WZA6gVAAAAgO2wqJdGVXVkkiO7Xz6qu312VZ3T/fNNrbU3Jklr7baqWpVOyPTZqjovyc1JjkiyT3f/+WOv31q7rqrelOTdSTZU1flJ7k5ydJLHJvnL1tqX+nmCAAAAAAxOT+FSkqcnecW4fU/oPpJkJMkbRw+01i6sqoOSvCXJUUl2SnJtktcneXdrrY3/Bq2191TVxu51jk1nVNVVSU5qrX2wxzoBAAAAmEE9hUuttVOSnLItF26tfSHJ87fxnIuTXLwt5wAAAAAwewax5hIAAAAAQ0K4BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9E24BAAAAEDfhEsAAAAA9G3RbBcAAAAMp+UnLs/IppGe2i5buiwbT9842IIA6ItwCQAAmBUjm0bS1ree2taqGnA1APRroNPiquoFVfXpqrq+qu6squ9V1Uer6tmTtN+/qj5RVTd3219ZVaur6kGDrBMAAACA/gwsXKqqM5L8U5LfTHJJkncl+XqSFyX5QlUdM679i5JckeTAJB9L8t4kD0myNsl5g6oTAAAAgP4NZFpcVT0qyRuT3Jjkaa21H485dkiSy5OcluTc7r5dk6xPcl+Sg1trG7r739pte3RVrWytCZkAAAAA5pBBrbm0LJ1RUV8ZGywlSWvtM1X10yR7jtl9dPfrvxsNlrpt76qqk5JcluQ1MYIJAACG0rKly3pad8nC3wAzb1Dh0jVJ7k7y21W1R2vtptEDVXVgkocluXBM+0O720smuNYVSbYk2b+qdmyt/WwwJQMAAHNVr4GRhb8BZt5A1lxqrd2c5I+TPDLJVVV1VlX9WVV9JMmnk1ya5H+OOWWf7va7E1zr3iTXpROEPWEQ9QIAAADQn0GNXEprbV1VbUzyt0lWjTl0bZJzxk2X2627vXWSy43uf/hk36+qjktyXJLstddefVQMAAAAwLYa5N3i3pzkgiTnJHlikp2T/FaS7yX5cFX9n+n8fq21s1prK1prK/bcc8+pTwAAAABguw0kXKqqg5OckeSi1trrW2vfa61taa19PcmLk/xXkjdU1eg0t9GRSbv90sV+cf8tg6gXAAAAgP4MalrcC7vbz4w/0FrbUlVfTSdkekY6I5muTrIiyd5Jvja2fVUtSvL4JPd22wIAAMCUlp+4PCObRqZs5y6DsH0GFS7t2N1ONj9tdP/d3e3lSf6/JM9N8g/j2h6YZHGSK9wpDgAAgF6NbBpJW9+mbOcug7B9BrXm0r92t8dV1a+MPVBVz0tyQJK7knyxu/uCJDclWVlVK8a03SnJ27pf/tWAagUAAACgT4MauXRBkn9J8ntJvl1VH0tyQ5InpzNlrpKc2FrblCSttduqalX3vM9W1XlJbk5yRJJ9uvvPH1CtAAAAAPRpIOFSa+3+qnp+kuOTrExnfaXF6QRGn0jy7tbap8edc2FVHZTkLUmOSrJTkmuTvL7bfuqxjAAAAADMqEGNXEpr7Z4k67qPXs/5QpLnD6gkAAAAAKbZoNZcAgAAAGAICJcAAAAA6NvApsUBAADAbFt32brZLgEWPCOXAAAAAOibkUsAAAAMzPITl2dk08iU7ZYtXZaNp28cfEHAtBMuAQAAMDAjm0bS1rcp29WqmoFqgEEwLQ4AAACAvgmXAAAAAOibcAkAAACAvgmXAAAAAOibcAkAAACAvgmXAAAAAOibcAkAAACAvgmXAAAAAOibcAkAAACAvi2a7QIAAABg2dJlqVXVc9uNp28cbEFAz4RLAAAAzLptCYt6DaGAmWFaHAAAAAB9M3IJAACYNesuWzfbJQCwnYxcAgAAAKBvwiUAAAAA+iZcAgAAAKBvwiUAAAAA+iZcAgAAAKBvwiUAAAAA+iZcAgAAAKBvwiUAAAAA+iZcAgAAAKBvwiUAAAAA+rZotgsAAACYq5afuDwjm0ambLds6bJsPH3j4AtiYNZdtm7KNqsPWz3wOmA+Ei4BAABMYmTTSNr6NmW7WlUzUA3A3GRaHAAAAAB9Ey4BAAAA0DfhEgAAAAB9s+YSAAAMUK8LQicWhWbhslg2LGzCJQAAGKBeF4ROLAoNwPxkWhwAAAAAfTNyCQAAgKG2ZPGSrDlvzZTt1l26ztRVmIBwCQAAgKF28hEn99SulwAKhpFpcQAAAAD0beAjl6rqsCSvTfLsJEuSbEryzSTvaq19Ylzb/ZOclORZSR6a5Jokf5vkPa21+wZdKwAAALOjlzvKJe4qB3PRQMOlqvo/Sd6U5PokFyW5KcmeSX4rycFJPjGm7YuS/GOSu5Kcn+TmJIcnWZvkgCQvHWStAAAAAGy7gYVLVbUqnWDpg0mOa63dPe74g8f8edck65Pcl+Tg1tqG7v63Jrk8ydFVtbK1dt6g6gUAAABg2w1kzaWq2jHJ25N8PxMES0nSWrtnzJdHpzOi6bzRYKnb5q50psklyWsGUSsAAAAA/RvUyKX/lk5YtC7J/VX1giRPTWfK21dba18a1/7Q7vaSCa51RZItSfavqh1baz8bTMkAAAAAbKtBhUvP7G7vSvKNdIKlB1TVFUmObq39pLtrn+72u+Mv1Fq7t6quS7Jvkick+fZE37CqjktyXJLstdde21s/AAAAAD0YyLS4JI/obt+UpCX53SQPS/K0JJ9OcmCSj45pv1t3e+sk1xvd//DJvmFr7azW2orW2oo999yzz7IBAAAA2BaDCpdGr3tvkiNaa59vrd3eWvtmkhenc/e4g6rq2QP6/gAAAADMgEFNi7ulu/1Ga23j2AOttS1V9akkf5jkt5N8KT8fmbRbJja6/5ZJjgMAwNBYfuLyjGwambLdsqXLsvH0jYMvCIChNqhw6eru9pZJjm/ubh86pv2KJHsn+drYhlW1KMnj0xkF9b1prRIAAOahkU0jaevblO1qVc1ANQAMu0FNi7ssnbWWnlJVE32P0QW+r+tuL+9unztB2wOTLE7yRXeKAwAAAJhbBjJyqbU2UlUXJzkiyQlJ1o4eq6rnJPl/0hnVdEl39wVJzkiysqre01rb0G27U5K3ddv81SBqBQCA+WjdZetmu4R5bVumFs51090XVh+2elqvByx8g5oWlyTHJ3lGkndW1QuSfCOd6W1HJrkvyataa7cmSWvttqpalU7I9NmqOi/JzemEU/t0958/wFoBAIAh0uvUQgCmNrBwqbV2fVX9VpKT0wmJDkxyW5KLk/xZa+2r49pfWFUHJXlLkqOS7JTk2iSvT/Lu1pp3fgAA2AbLli7rad0lC38DsD0GOXIprbWfJPmj7qOX9l9I8vxB1gQAAMOi18DIwt8AbI9BLegNAAAAwBAY6MglAABg9lj0m7FOu+i0bN6yecp26y5dZ5oksE2ESwAAAENg85bNWbty7ZTt1py3ZgaqARYS0+IAAAAA6JtwCQAAAIC+CZcAAAAA6JtwCQAAAIC+WdAbAACAbeZuhDNnW/6uVx+2emB1wGSMXAIAAACgb0YuAQAwo5afuDwjm0ambLds6bJsPH3j4AtiaC2UkTenXXRaNm/ZPGW7JYuXzEA1wDASLgEAMKNGNo2krW9TtqtVNQPVwPy3ecvmrF25drbLAIaYaXEAAAAA9M3IJQAAZtxCmY7ExLy+ML16nfqYJOsuXWdKMTNOuAQAAABz2LZMfVxz3poBVwO/zLQ4AAAAAPpm5BIAwBDqddrS6sNWD7SOYWGaGAALmZFLAAAAAPRNuAQAAABA30yLAwAAepq6Z5rk1vk7hJm3/MTlGdk00lPbZUuXuZPegAiXAAAAgHlpZNNI2vrWU9taVQOuZngJlwAAALbTksVLeroF/LpL1y2YkROnXXRaNm/ZPGW7JYuXzEA1jGUUHTNNuAQAALCdTj7i5J7a9RJAzRebt2zO2pVrZ7sMYA6woDcAAAAAfTNyCQCASfUytSIxvQIAhpmRSwAAAAD0TbgEAAAAQN9MiwMAYFK93g1qId0BC+aCXqekAswFwiUAACbV692gFtIdsACAbSNcAgAAplWvI96WLF4yA9XAcFmyeElPgb8Rp0wn4RIAADCteh3xBky/k484uad2RpwynSzoDQAAAEDfjFwCAGDO6mVR49WHrR54HQDA5IxcAgAAAKBvwiUAAAAA+mZaHAAADDl3lwJgewiXAABgyLm7FADbw7Q4AAAAAPpm5BIAAIyx/MTlGdk0MmW7ZUuXmSIGMAf0cmdRBku4BAAAY4xsGklb36ZsV6tqBqoBgLlvRsOlqjomyYe6X65qrf3NBG1emOSNSZ6R5EFJ/iPJ+1trH5yxQgEAZsh0j5Lp9Xq9WrJ4ybRdC2C+W7Z0WU/BspGNDJsZC5eq6nFJ3pvk9iS7TNLmtUnek2RTknOT3J3k6CTnVNWvt9beOEPlAgDMiOkeJdPr9UwhANh2vQZGRjYybGZkQe+qqiRnpxManTlJm+VJ/iLJzUlWtNaOb62tSfK0JP+Z5A1V9eyZqBcAAACA3szUyKXXJTk0ycHd7UT+R5Idk5zRWts4urO1trmq3pHkA0leneRLA60UAGCeMypp+/k7BIDeDXzkUlU9OcnpSd7VWrtiK01HQ6dLJjj2yXFtAAAAAJgDBhouVdWidBbw/n6SP5mi+T7d7XfHH2it/SjJHUkeW1WLp7VIAAAAAPo26GlxJ6dz17ffaa3dOUXb3brbWyc5fmuSnbvttow/WFXHJTkuSfbaa6++igUAgG1h+hyDctpFp2Xzls09tXVXR2C2DSxcqqr90hmt9JettYGvk9RaOyvJWUmyYsWKqW+RAgAAMEdt3rI5a1eune0yAHoykGlx3elwf5fOFLe39nja6Iil3SY5PtXIJgAAAABm2KBGLu2SZO/un++qqonarK+q9eks9L06ydVJ9uie9wsjnarq0elMibu+tfZLU+IAAOYa06Vmzu4n7N7T9KFlS5dl4+kbB18QAAyZQYVLP0vygUmO/WY66zB9Pp1AaTRIujzJAUmem3HhUpLnjWkDAAAP6HX60Jrz1sxANQAwfAYSLnUX737VRMeq6pR0wqUPttb+Zsyhs5O8Oclrq+rs1trGbvsl+fmd5s4cRL0AAAAwFaNSYWKDvltcz1pr11XVm5K8O8mGqjo/yd1Jjk7y2MzQwuAAAAAA9G7OhEtJ0lp7T1VtTPLGJMems+D4VUlOaq19cDZrAwAAAOCXzXi41Fo7JckpWzl+cZKLZ6oeAIDZZpoFADCf7TDbBQAAAAAwfwmXAAAAAOjbnFpzCWDYLT9xeUY2jUzZbtnSZdl4+sbBFzQP9Tq9aPVhqwdaB7D9lixekjXnrempHQCDsfsJu2fzls1TtvP5dLgJlwDmkJFNI2nr25TtalXNQDUAs+vkI06e7RIAht7mLZuzduXaKdv18ssAFi7hEgAw7xjlBwAwdwiXAIB5xyg/AIC5w4LeAAAAAPTNyCUAAOiDBceB7dXrjUhgrhMuAQBAHyw4DgAdpsUBAAAA0DcjlwBYUE676LRs3rJ5ynbrLl3nLmIAADANhEsALCibt2zO2pVrp2zXyzopAADA1EyLAwAAAKBvRi4BzDHuGgIAAMwnRi4BAAAA0DcjlwAABqDXxeWXLF4yA9UAAAyOcAkAYAB6XVweAGC+My0OAAAAgL4ZuQQAAABst15uTLP6sNUDr4OZZ+QSAAAAAH0TLgEAAADQN+ESAAAAAH0TLgEAAADQN+ESAAAAAH1ztzgAkiTLT1yekU0jU7ZbtnRZNp6+cfAFwRzUy11wAKBXp110WjZv2TxluyWLl8xANdA/4RIASZKRTSNp69uU7WpVzUA1AAAL3+Ytm7N25drZLgO2m3AJgHmh15FV8+E3e0aJAQALzZLFS7LmvDVTtlt36TqfbxYg4RIA80KvI6vmw7Qlo8QAgIXm5CNO7qldLwEU848FvQEAAADom5FLAEDfeh0ptvqw1QOtY6b0uvBqMj+maALAbOjl88MgPjssW7qsp5Hh/g/fdsIlAIAeWXgVAOavXtd6mg/LLMw1psUBAAAA0DcjlwCAeclvFQFg/pnNu8r57DA4wiUAAABgRrir3MJkWhwAAAAAfRMuAQAAANA34RIAAAAAfbPmEjDjel1Ib/VhqwdaB8Nt2dJlqVXVc9vpXlASAAAWCuESAENpW8KiXkMoAAAYRqbFAQAAANC3gY1cqqqlSV6c5AVJfj3JryS5O8k3k5yd5OzW2v0TnLd/kpOSPCvJQ5Nck+Rvk7yntXbfoOoFtt/uJ+yezVs2T9luyeIlPd+ClJnV65RFGBR9EABg/hnktLiXJvmrJD9K8pkk30/yyCQvSfI3SZ5XVS9trbXRE6rqRUn+McldSc5PcnOSw5OsTXJA95rAHLV5y+asXbl2ynZrzlszA9UAAAAwEwYZLn03yRFJ/nnsCKWq+pMkX01yVDpB0z929++aZH2S+5Ic3Frb0N3/1iSXJzm6qla21s4bYM0AAAAAbIOBhUuttcsn2X9DVZ2Z5O1JDk43XEpydJI9k/zdaLDUbX9XVZ2U5LIkr0kiXAIYUtM5Zcr0q+HRy2vt7pQAAP2brQW97+lu7x2z79Du9pIJ2l+RZEuS/atqx0EWBgAAAEDvBjktbkJVtSjJsd0vxwZJ+3S33x1/Tmvt3qq6Lsm+SZ6Q5NsTXPe4JMclyV577TWdJTPPLT9xeUY2jUzZbtnSZdt0a3IAAABgFsKlJKcneWqST7TWPjVm/27d7a2TnDe6/+ETHWytnZXkrCRZsWJFm6gNw2lk00ja+qm7RK2qGagGAAAAFpYZnRZXVa9L8oYk30ny8pn83gAAAABMvxkLl6rqtUneleSqJIe01m4e12R0ZNJumdjo/lumvzoAAAAA+jEj4VJVrU7yniTfSidYumGCZld3t3tPcP6iJI9PZwHw7w2oTAAAAAC20cDDpar64yRrk/x7OsHSjydpenl3+9wJjh2YZHGSL7bWfjbtRQIAAADQl4Eu6F1Vb01yWpKvJXnOBFPhxrogyRlJVlbVe1prG7rX2CnJ27pt/mqQ9cJCsO6ydT23XX3Y6oHVAcNoW/79zQZ3zwQAYBAGFi5V1SvSCZbuS/KvSV5X9Ut349rYWjsnSVprt1XVqnRCps9W1XlJbk5yRJJ9uvvPH1S9ALDQuXsmAACDMMiRS4/vbh+UZPUkbT6X5JzRL1prF1bVQUnekuSoJDsluTbJ65O8u7U29SdiYOj0OlrESK2ZNYyjZE676LRs3rJ5ynbLli6bgWq2z1wfhQUAwNwxsHCptXZKklP6OO8LSZ4/3fUAMLOGcZTM5i2bs3bl2inbCToBAFhIZuRucQAAAAAsTANd0BvmimGa3tHrtJwkWXfpugUxHanX57xQnu9cMEz/pgZhIf39+fcHAIBwCRaYXqflJMma89YMuJqZ0etzXijPF+YS//4AADAtDgAAAIC+GbkEAHNYL1PoLBAOAMBsMnIJAAAAgL4JlwAAAADom2lxADNg+YnLM7JpZMp2SxYv6el6y5YuS62qntq5QxcAADBIwiWAGTCyaSRtfZuyXa+3qO81MOolgAIAANgewiXoWrJ4iZEgwJyyZPGSrDlvzZTt1l26ruf3pV4CzF6/72jb6XTaRadl85bN0/Z9B/F3CADALxIuQdfJR5zcU7tef+AC2F6z9b7U6/cdhM1bNmftyrXTdj3v7QAAg2dBbwAAAAD6ZuQSMONma5pKr1MfE9Mfp0uva0gBAADzl3AJmHHzYaqPKTIAAAC9MS0OAAAAgL4ZuQQwQ6ZzithsTjfrdVrjdN9FDAAAmJuESwBsk9m8kxgAADD3mBYHAAAAQN+MXIJZ1uv0pnWXrsvIppEp2w1iKpI7fgEAADAZ4RLMEyObRtLWtynbCYIAAACYSabFAQAAANA34RIAAAAAfRMuAQAAANA3ay6xXaZ7fZ/Vh62e1usNSi/PexDPxXpKM2u2XmcAAID5xMglAAAAAPomXAIAAACgb6bFsV1Ou+i0bN6yecp2SxYvyclHnDwDFTEI2/I6AwAAMFyES2yXzVs2Z+3KtVO2W3PemhmohkHp9XUGAABg+AiXYJYZFQQAAMB8JlyCWWZUEAAAAPOZBb0BAAAA6JuRS8wp6y5b11O71YetHmgdAAAAQG+MXAIAAACgb8IlAAAAAPpmWhwzYsniJVlz3pqe2p18xMkzUFH/en0u6y5dl42nbxx8QQyE1xkAAJhKL0u7DMOyLsIlZkSvgVEvP8zPtoX0XJic1xkAAKA3psUBAAAA0Dcjl5hTTEUCAACA+UW4xJxiKhIAAADML3MuXKqqxyY5LclzkyxN8qMkFyY5tbW2eRZLWxB6WWwsGY4FxwAAAIDtN6fCpap6YpIvJnlEko8n+U6S305yQpLnVtUBrbVNs1giAAAAAGPMtQW9359OsPS61tqRrbUTW2uHJlmbZJ8kb5/V6gAAAAD4BXNm5FJ31NJzkmxM8r5xh/93kuOSvLyq3tBau2OGy5sVu5+wezZvmd6ZgEsWL+l5XSMAAABgYm5I9XNzJlxKckh3++nW2v1jD7TWflpVX0gnfHpWkstmurjZsHnL5qxduXZar2khbAAAANh+bkj1c3NpWtw+3e13Jzl+TXe79wzUAgAAAEAPqrU22zUkSarqrCSrkqxqrf3NBMffnuRPkvxJa+3PJjh+XDpT55JOUHX1AMtlduyR5KbZLoI5Sd9ga/QPJqNvMBl9g8noG2yN/sFkFlLfWNZa23P8zrk0LW67tNbOSnLWbNfB4FTVhtbaitmug7lH32Br9A8mo28wGX2DyegbbI3+wWSGoW/MpWlxt3a3u01yfHT/LYMvBQAAAIBezKVwaXQa22RrKv1adzvZmkwAAAAAzLC5FC59prt9TlX9Ql1V9bAkByTZkuTLM10Yc4Zpj0xG32Br9A8mo28wGX2DyegbbI3+wWQWfN+YMwt6J0lVfSrJc5K8rrX2njH735lkTZK/bq29erbqAwAAAOAXzbVw6YlJvpjkEUk+nuTbSfZLckg60+H2b61tmr0KAQAAABhrToVLSVJVj0tyWpLnJlma5EdJPpbk1Nba5tmsDQAAAIBfNOfCJQAAAADmj7m0oDdDqKqWVtWrqupjVXVtVd1ZVbdW1eer6g/HL+4+5rz9q+oTVXVz95wrq2p1VT1opp8Dg1NVZ1TVZVX1g+7rfHNVfaOq/ndVLZ3kHH1jSFXVMVXVuo9XTdLmhVX12e77zO1V9ZWqesVM18pgVdXGMX1h/OOGSc7x3jFEquqw7mePG6rqZ1X1w6r6VFU9f4K2+sYCV1Wv3Mp7xujjvgnO0zeGRFW9oKo+XVXXd1/r71XVR6vq2ZO01zeGQHWs6n6evL2q7qiqDVX16q38HLtgP4saucSsqqpXJ/mrdKY/fibJ95M8MslLkuyW5B+TvLSN6ahV9aLu/ruSnJ/k5iSHJ9knyQWttZfO5HNgcKrq7iRfT3JVkh8n2TnJs5KsSPLDJM9qrf1gTHt9Y0h1p1R/M8mDkuySZFVr7W/GtXltkvck2ZRO/7g7ydFJHpvkL1trb5zRohmYqtqY5OFJ1k1w+PbW2l+Ma++9Y4hU1f9J8qYk1yf5ZJKbkuyZ5LeS/Etr7c1j2uobQ6Cqnp7kyEkO/26SQ5P8c2vthWPO0TeGRFWdkeTN6Xx+uDCd94xfTXJEkkVJjm2tnTumvb4xJKrqw0n+ezo/p1yUzt3t/1uSJyf5UGvt2HHtF/Zn0daah8esPdL5z/rwJDuM2/+odIKmluSoMft3Tecf78+SrBizf6d0FoNvSVbO9vPymLb+sdMk+9/efa3fr294JKkk/5LkP5P8efe1ftW4NsvT+ZC3KcnyMfuXJLm2e86zZ/u5eExbn9iYZGOPbb13DNEjyarua3pOkodMcPzB+obHuD7xpe5rfYS+MXyP7s8k9yW5Ickjxh07pPtaf0/fGL5HkhePvv5J9hiz/yFJLu4ee8mY/Qv+s6hpccyq1trlrbWLW2v3j9t/Q5Izu18ePObQ0en8dvG81tqGMe3vSnJS98vXDK5iZlL3dZ3IR7rbXxuzT98YXq9LJ6j+gyR3TNLmfyTZMcl7W2sbR3e2zo0i3tH98tUDrJG5y3vHkKiqHdP55cT3kxzXWrt7fJvW2j1jvtQ3hlxV/Xo6I6b/K8k/jzmkbwyPZeksJfOV1tqPxx5orX0myU/T6Quj9I3h8eLu9i9bazeN7uz+3/LW7pevHdN+wX8WXTTbBcBWjH7Au3fMvkO720smaH9FOkMR96+qHVtrPxtkccyqw7vbK8fs0zeGUFU9OcnpSd7VWruiqg6dpOnW+scnx7VhYdixqo5Jslc6oeOVSa5orY1fN8V7x/D4b+n80Lcuyf1V9YIkT03nN8lfba19aVx7fYPjutsPjHvv0DeGxzXpTF367araY2yIUFUHJnlYOlPlRukbw+NR3e33Jjg2uu93q+oh3cBpwX8WFS4xJ1XVoiSjc1TH/gPcp7v97vhzWmv3VtV1SfZN8oQk3x5okcyYqnpjOuvo7JbOeku/k84PiqePaaZvDJnu+8SH0hmF8CdTNN9a//hRVd2R5LFVtbi1tmV6K2WWPCqd/jHWdVX1B621z43Z571jeDyzu70ryTfSCZYeUFVXJDm6tfaT7i59Y4hV1UOTHJPOlKi/GXdY3xgSrbWbq+qPk7wzyVVVdWE605qemM6aS5cm+Z9jTtE3hsdo0Pj4CY49obtd1P3zdzIEn0VNi2OuOj2dD32faK19asz+3brbWyc5b3T/wwdUF7PjjUn+d5LV6QRLlyR5zpgfABJ9YxidnOQZSV7ZWrtzira99o/dJjnO/HJ2ksPSCZh2TvLrSf46nfUOPllVvzGmrfeO4fGI7vZN6axt8bvpjDp4WpJPJzkwyUfHtNc3htvL0nltL2ljbh7SpW8MkdbaunRuNrQonXXbTkzy0iQ/SHLOuOly+sbwGJ0q+/qq2n10Z1U9OMmpY9ot6W4X/GdR4RJzTlW9Lskb0kl4Xz7L5TAHtNYe1VqrdH5QfEk6vwH4RlX95uxWxmypqv3SGa30lxNMZWHItdZO7a7pd2NrbUtr7VuttVen85vnhyY5ZXYrZJaMfu69N53FmT/fWru9tfbNdNbOuD7JQZPdWpyhMzol7q9ntQpmXVW9OckF6dwI4Inp/NLit9KZ+vTh7h0oGT7nJflUOn3iqqr666p6V5J/T+eXF9/vtrt/4tMXHuESc0r39ozvSufW84e01m4e12SqRHd0/y3TXx2zrfuD4seSPCfJ0iR/N+awvjEkutPh/i6dYcVvnaL5qF77x2S/TWJhGL1RxIFj9nnvGB63dLffGLuYapJ0pyCMjpT+7e5W3xhSVbVvkv3TCRw/MUETfWNIVNXBSc5IclFr7fWtte91f2nx9XRC6f9K8oaqGp0GpW8Mie46bIenM5LtJ0le0X1ck877x0+7TUdHti34z6LCJeaMqlqd5D1JvpVOsHTDBM2u7m73nuD8RenMeb03Ey+sxgLRWhtJJ4Dct6r26O7WN4bHLum8zk9OcldVtdFHOtMnk2R9d9+67tdb6x+PTue3kNfP1znu9Gx0Ku3OY/Z57xgeo6/1LZMc39zdPnRce31j+Ey2kPcofWN4vLC7/cz4A93PDF9N52fqZ3R36xtDpLV2T2vtjNbar7fWdmqtPby1dmSSjenc1fqm1tp13eYL/rOocIk5obtQ3tp0hhEeMv5Wn2Nc3t0+d4JjByZZnOSL7r4wFB7T3Y5+6NM3hsfPknxgksc3um0+3/16dMrc1vrH88a1YeF6Vnc79kO9947hcVk6ay09paom+gw8usD36A8C+sYQqqqd0lmW4b50/h+ZiL4xPHbsbvec5Pjo/ru7W32DJFmZ5CFJ/mHMvoX/WbS15uExq490prW0JBuS7D5F213T+c3zz5KsGLN/pyRf7F5n5Ww/J49p6Rd7J9ltgv07JHl797X+gr7hMa5/nNJ9rV81bv/j07lD1KYky8fsX5Lk2u45z57t+j2mpQ88OcnOE+xfns5Q9ZbkT8bs994xRI8kH+++pmvG7X9OOutibB79v0ffGM5HOsFSS3LxVtroG0PySGdh95bkhiS/Mu7Y87rvG3cmWapvDN8jya4T7Ht6tw/cnOQxY/Yv+M+i1X1CMCuq6hXpLI53XzpT4iaaY7qxtXbOmHOOTGdRvbvSWUjt5nRuBbpPd//Lmo4973WnSf5ZOiNQrkvnjfiRSQ5KZ0HvG5Ic1lq7asw5R0bfGGpVdUo6U+NWtdb+ZtyxP0ry7nT60vnp/Jbx6CSPTWdh8DfObLUMQrcPvCHJFUlG0lnz4IlJXpDOh/tPJHlxa+3uMeccGe8dQ6GqHpvOD3iPS2ck0zfS+cB/ZH7+Q98/jml/ZPSNoVJV/5rOnWmPaK1dvJV2R0bfWPC6oxw/leT30vn/5GPpfAZ9cjpT5irJ6tbau8acc2T0jaFQVV9JJ1z8Vjr948npfN64M8nhrbXPjWu/oD+LCpeYVWN+ENyaz7XWDh533gFJ3pLk2en8sHBtkr9N8u428dx45pmqemqSV6fzAe+x6dyy9Y50FnH+53Re6/ELvusbQ25r4VL3+OFJ3pjkN9MZBXdVkve21j44k3UyOFV1UDrvHc9I5w6TO6ezxs6/J/lQkg9N9KHee8fwqKo9k5yczg97j05yW5J/TfJnrbWvTtBe3xgSVfXkdP5fuD6dkQVbfX31jeHQvbX88elMdXpKOlPbbk5nvaV3t9Y+PcE5+sYQqKo3pdMvnpjOen3/leST6fx/cv0k5yzYz6LCJQAAAAD6ZkFvAAAAAPomXAIAAACgb8IlAAAAAPomXAIAAACgb8IlAAAAAPomXAIAAACgb8IlAAAAAPomXAIAAACgb8IlAAAAAPr2/wNE8cvfO830mAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "\n",
    "plt.hist(np.round(data_sc.inverse_transform(results)), bins = 100, histtype = 'step',color='darkgreen',label=\"GAN\")\n",
    "plt.hist(data, bins = 100,color='darkseagreen', label= \"True\")\n",
    "# plt.xlim(data.min(),data.max())\n",
    "plt.legend(loc = 'upper center', fontsize = 25, frameon = 0)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "#plt.savefig(\"Gan.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
